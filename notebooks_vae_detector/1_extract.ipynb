{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  実験目標\n",
    "- 一局を通して現れる異常な行動を画像ベースで取得する\n",
    "\n",
    "## 実験手順\n",
    "- 棋譜から評価値を読み込む -> ok\n",
    "- 「指し手から次の指し手」までの間隔を画像ベースで把握する -> ok\n",
    "- 初手から10手をニュートラルの姿勢とし、異常検知をして画像を収集する -> ok\n",
    "    - 初手から10手の画像とpose抽出画像をそれぞれaddWeightedで重ねる -> ok\n",
    "    - 2種類の画像を基準に異常な行動画像を抽出\n",
    "        - 10手で作成した合成画像から外れ値となるしきい値を生成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モジュールの読み込み\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"\\nfont.family\" on line 618 in\n",
      "/home/nvidia/.pyenv/versions/3.5.2/lib/python3.5/site-packages/matplotlib/mpl-data/matplotlibrc.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['font.family'] = 'IPAPGothic'\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import imagehash\n",
    "from PIL import Image\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from glob import glob\n",
    "\n",
    "# 特徴量抽出\n",
    "from DeNAPose.pose_detector import PoseDetector, draw_person_pose\n",
    "\n",
    "from multiprocessing import Pool\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final1は藤井先生が後手なのでフラグをFalseへ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_thresh = 5 # openposeによるスケルトン抽出時の信頼度スコアのしきい値\n",
    "sampling_frame_rate = 6 # サンプリングレート\n",
    "isFujii = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データフレームの作成と出力\n",
    "# 棋譜データの読み込みとデータフレーム作成\n",
    "# kifデータを合わせる\n",
    "with open(\"../data/kif/AbemaTV_Tournament_Final1_analized.kif\", encoding=\"utf-8\") as f:\n",
    "    kif = f.readlines()\n",
    "shogi_df = pd.DataFrame([int(k.split(\" \")[1]) for k in kif if \"*##\" in k], columns=[\"score\"])\n",
    "\n",
    "if not isFujii:# 後手番なら評価値を逆にする\n",
    "    shogi_df[\"score\"] = shogi_df[\"score\"] * -1\n",
    "shogi_df['score_label'] = shogi_df[\"score\"].map(lambda x: x//300)\n",
    "shogi_df[\"hand_number\"] = shogi_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 評価値が変化するまでと定義したときのthreshold\n",
    "# 0が連続しているところまでを抽出\n",
    "score0_idx = shogi_df[shogi_df.score == 0].index.values\n",
    "threshold = score0_idx[np.where(np.diff(score0_idx) <= 3)[0][-1] + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trimming(img):\n",
    "    mask = img < 255\n",
    "    x = np.where(np.sum(mask, axis=0) > 1)[0]\n",
    "    y = np.where(np.sum(mask, axis=1) > 1)[0]\n",
    "    \n",
    "    x_min, x_max = x[0], x[-1]\n",
    "    y_min, y_max = y[0], y[-1]\n",
    "    return x_min, x_max, y_min, y_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_preprocess(img):\n",
    "    size = 32\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # openposeのミスをできるだけ前処理で落とす\n",
    "#     try:\n",
    "    x, w, y, h = trimming(img)\n",
    "    margin = 16\n",
    "    img_trim = img[y-margin:h+margin, x-margin:w+margin]\n",
    "    height, width = img_trim.shape\n",
    "\n",
    "    if (height < 150) or (width < 150):\n",
    "        return np.zeros((size, size))\n",
    "\n",
    "    # 膨張処理\n",
    "    kernel = np.ones((6,6),np.uint8)\n",
    "    img_trim = cv2.bitwise_not(img_trim) # 白(255)を膨張させるため反転\n",
    "    img_dil = cv2.dilate(img_trim,kernel,iterations = 1)\n",
    "\n",
    "    img_dil = cv2.resize(img_dil, (size, size))\n",
    "\n",
    "    # 2値化\n",
    "    _,img_bin = cv2.threshold(img_dil,0,1,cv2.THRESH_BINARY)\n",
    "\n",
    "    return img_bin * 255.0\n",
    "#     except:\n",
    "#         return np.zeros((size, size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def extract(start, end, isFujii, output_path, cap):\n",
    "    for i in tqdm(range(start, end), leave=False):\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, sampling_frame_rate*i)\n",
    "        frame = cv2.cvtColor(cap.read()[1], cv2.COLOR_BGR2RGB)\n",
    "        pose_rect = cv2.flip(frame[678:968, 45:565].copy(), 1) if isFujii else frame[220:510, 1340:1860].copy()\n",
    "        pose_keypoints, scores = pose_detector(pose_rect)\n",
    "\n",
    "        if len(np.where(scores > pose_thresh)[0]) == 0:\n",
    "            # 真っ白な画像を作成\n",
    "            img_skel = np.ones_like(pose_rect, dtype=np.uint8) * 128\n",
    "            img_skel = img_preprocess(img_skel)\n",
    "        else:\n",
    "            img_skel = draw_person_pose(np.full_like(pose_rect, 255), pose_keypoints[np.where(scores > pose_thresh)])\n",
    "            img_skel = img_preprocess(img_skel)\n",
    "        \n",
    "        \n",
    "        if not os.path.isdir(output_path):\n",
    "            os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "        cv2.imwrite(os.path.join(output_path, \"img_frame{:06d}.png\".format(sampling_frame_rate*i)), img_skel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root_path = \"/media/nvidia/JetsonTX2SSD240/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the model...\n"
     ]
    }
   ],
   "source": [
    "pose_detector = PoseDetector(\"posenet\", \"../utils/DeNAPose/models/coco_posenet.npz\", device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AbemaTV_Tournament_final1_abnorm_supervised.mp4\r\n",
      "AbemaTV_Tournament_final1_abnorm_supervised_v2.mp4\r\n",
      "AbemaTV_Tournament_Final1.mp4\r\n",
      "AbemaTV_Tournament_Final2.mp4\r\n",
      "AbemaTV_Tournament_Final3.mp4\r\n",
      "final1_labeling.mp4\r\n",
      "fujii_vs_kondo_Ablock_1_1080p.mov\r\n",
      "fujii_vs_kondo_Ablock_2_1_1080p.mov\r\n",
      "fujii_vs_kondo_Ablock_2_2_1080p.mov\r\n",
      "fujii_vs_takami_semi_1_1080p.mov\r\n",
      "fujii_vs_takami_semi_2_1080p.mov\r\n",
      "fujii_vs_takami_semi_3_1080p.mov\r\n",
      "shogi_pose_dataset\r\n",
      "sup_or_inf\r\n",
      "sup_or_inf_20181102\r\n",
      "sup_or_inf_20181113\r\n",
      "sup_or_inf_20181114\r\n",
      "sup_or_inf_20181115\r\n"
     ]
    }
   ],
   "source": [
    "!ls /media/nvidia/JetsonTX2SSD240/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = sorted(glob(\"/media/nvidia/JetsonTX2SSD240/data/AbemaTV_Tournament_final1_abnorm_supervised.mp4\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data_path += sorted(glob(data_root_path + \"*.mov\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/media/nvidia/JetsonTX2SSD240/data/AbemaTV_Tournament_final1_abnorm_supervised.mp4']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fujii_bw = [False, True, False, True, False, False, True, False, True]\n",
    "fujii_bw = [False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/nvidia/JetsonTX2SSD240/data/shogi_pose_dataset/AbemaTV_Tournament_final1_abnorm_supervised\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10322), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for vid, fuji in zip(data_path, fujii_bw):\n",
    "    output_path = os.path.join(data_root_path, \"shogi_pose_dataset/{}\".format(vid.split(\"/\")[-1].split(\".\")[0]))\n",
    "    print(output_path)\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    cap = cv2.VideoCapture(vid)\n",
    "    total = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))//sampling_frame_rate\n",
    "    extract(0, total, fuji, output_path, cap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def wrapper(args):\n",
    "    return extract(*args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with tqdm(total=total) as pbar:\n",
    "    with Pool(mp.cpu_count()) as p:\n",
    "        for _ in tqdm(enumerate(p.imap_unordered(wrapper, splits))):\n",
    "            pbar.update()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
